# API de Transcripci√≥n con WhisperX y Diarizaci√≥n

![Python](https://img.shields.io/badge/Python-3.10-blue.svg)
![Docker](https://img.shields.io/badge/Docker-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100.0-green.svg)

Una API de alto rendimiento para la transcripci√≥n de audio a texto con identificaci√≥n de hablantes (diarizaci√≥n). El proyecto utiliza **WhisperX** para una transcripci√≥n precisa y una alineaci√≥n de tiempo, y est√° completamente empaquetado con **Docker** y **Docker Compose** para un despliegue sencillo en cualquier entorno.

## ‚ú® Caracter√≠sticas Principales

* **Transcripci√≥n de Alta Precisi√≥n**: Utiliza el modelo `large-v2` de Whisper a trav√©s de `whisperx` para obtener transcripciones de m√°xima calidad.
* **Diarizaci√≥n de Hablantes**: Identifica y etiqueta qui√©n habl√≥ y cu√°ndo, gracias a la integraci√≥n con `pyannote.audio`.
* **Optimizado para CPU y GPU**: Detecta autom√°ticamente si hay una GPU con CUDA disponible para acelerar el proceso. En CPU, se optimiza para usar m√∫ltiples hilos.
* **F√°cil de Desplegar**: Gracias a Docker, la configuraci√≥n es m√≠nima. Solo necesitas un comando para tener la API funcionando.
* **API Robusta**: Construida con FastAPI, ofrece una interfaz moderna, r√°pida y con documentaci√≥n autom√°tica.
* **Manejo Eficiente de Memoria**: Los modelos se cargan una sola vez al iniciar la aplicaci√≥n y se gestiona la memoria para un rendimiento estable.

## üõ†Ô∏è Stack Tecnol√≥gico

* **Backend**: Python, FastAPI
* **Transcripci√≥n**: WhisperX
* **Diarizaci√≥n**: Pyannote.audio
* **Contenerizaci√≥n**: Docker, Docker Compose
* **Inferencia de IA**: PyTorch, CTranslate2

## üöÄ C√≥mo Empezar

Sigue estos pasos para poner en marcha la API en tu m√°quina local.

### Prerrequisitos

* [Docker](https://www.docker.com/get-started) y [Docker Compose](https://docs.docker.com/compose/install/) instalados.
* [Git](https://git-scm.com/) para clonar el repositorio.
* **Un token de acceso de Hugging Face**: La diarizaci√≥n lo requiere para descargar el modelo de `pyannote`.
    1.  Crea una cuenta en [Hugging Face](https://huggingface.co/).
    2.  Ve a tu perfil -> **Settings** -> **Access Tokens**.
    3.  Crea un nuevo token con rol de `read`.
    4.  Copia el token.

### Instalaci√≥n y Ejecuci√≥n

1.  **Clona el repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/transcription-api.git](https://github.com/tu-usuario/transcription-api.git)
    cd transcription-api
    ```

2.  **Configura tu token de Hugging Face:**
    Abre el archivo `docker-compose.yml` y reemplaza el valor `token_de_hugging_face` con tu token real.
    ```yaml
    services:
      transcription-api:
        build: .
        ports:
          - "8002:8000"
        restart: unless-stopped
        environment:
          # Pega aqu√≠ el token que copiaste de Hugging Face
          - HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # <-- P√âGALO AQU√ç
    ```

3.  **Construye e inicia el contenedor:**
    Este comando construir√° la imagen de Docker (puede tardar varios minutos la primera vez) e iniciar√° la API.
    ```bash
    docker-compose up --build
    ```
    Si quieres que se ejecute en segundo plano, a√±ade el flag `-d`:
    ```bash
    docker-compose up --build -d
    ```

¬°Listo! La API estar√° disponible en `http://localhost:8002`.

## üé§ C√≥mo Usar la API

Env√≠a una petici√≥n `POST` al endpoint `/transcribir/` con tu archivo de audio.

### Endpoint: `POST /transcribir/`

* **Descripci√≥n**: Recibe un archivo de audio y devuelve la transcripci√≥n con los segmentos y hablantes identificados.
* **Cuerpo de la Petici√≥n**: `multipart/form-data` con un campo `audio_file`.

### Ejemplo con `curl`

Abre tu terminal y ejecuta el siguiente comando, reemplazando `/ruta/a/tu/audio.mp3` con la ruta real de tu archivo de audio.

```bash
curl -X 'POST' \
  'http://localhost:8002/transcribir/' \
  -F 'audio_file=@/ruta/a/tu/audio.mp3'
```

### Ejemplo de Respuesta Exitosa (JSON)

Recibir√°s un objeto JSON con una clave `segments` que contiene una lista de los fragmentos de texto detectados. Cada segmento incluye el texto, el tiempo de inicio y fin, y el hablante identificado.

```json
{
  "segments": [
    {
      "start": 0.53,
      "end": 2.77,
      "text": " Hola, este es un audio de prueba.",
      "speaker": "SPEAKER_01"
    },
    {
      "start": 3.12,
      "end": 5.45,
      "text": " Y esta es una segunda intervenci√≥n para verificar la diarizaci√≥n.",
      "speaker": "SPEAKER_00"
    }
  ]
}
```

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Uso de GPU (NVIDIA)

Si tu m√°quina tiene una GPU NVIDIA compatible con CUDA y los drivers instalados, puedes acelerar enormemente el proceso.

1.  Aseg√∫rate de tener instalado el [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html).
2.  En el archivo `docker-compose.yml`, descomenta la secci√≥n `deploy`:

    ```yaml
    # --- SECCI√ìN OPCIONAL PARA GPU NVIDIA ---
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ```
3.  Reinicia el contenedor: `docker-compose up --build -d`.

La aplicaci√≥n detectar√° la GPU autom√°ticamente y usar√° `float16` para un rendimiento √≥ptimo.

### Estructura de Archivos

```
.
‚îú‚îÄ‚îÄ docker-compose.yml  # Orquesta el despliegue del contenedor.
‚îú‚îÄ‚îÄ Dockerfile          # Define la imagen de Docker para la aplicaci√≥n.
‚îú‚îÄ‚îÄ main.py             # L√≥gica de la API con FastAPI y WhisperX.
‚îî‚îÄ‚îÄ requirements.txt    # Dependencias de Python.
```

## üìÑ Licencia

Este proyecto est√° distribuido bajo la Licencia MIT. Consulta el archivo [LICENSE](LICENSE) para ver los t√©rminos completos.